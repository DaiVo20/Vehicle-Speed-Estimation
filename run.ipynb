{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_helpers import *\n",
    "from tracking_helpers import *\n",
    "from bridge_wrapper import *\n",
    "from PIL import Image\n",
    "\n",
    "# detect ONLY [person,horses,sports ball]. class = None means detect all classes. List info at: \"data/coco.yaml\"\n",
    "detector = Detector(classes = [0, 17, 32])\n",
    "detector.load_model('yolov7x.pt')\n",
    "\n",
    "# Pass in any image path or Numpy Image using 'BGR' format\n",
    "# plot_bb = False output the predictions as [x,y,w,h, confidence, class]\n",
    "result = detector.detect('./IO_data/input/images/horses.jpg', plot_bb=True)\n",
    "\n",
    "# If it is image, convert it to proper image. Detector will give \"BGR\" image\n",
    "if len(result.shape) == 3:\n",
    "    result = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)) \n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run consumer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      " Convert model to Traced-model... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhc\\anaconda3\\envs\\speed\\lib\\site-packages\\torch\\nn\\modules\\module.py:675: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:485.)\n",
      "  if param.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "Loading detected frame from file...\n",
      "Processed frame no: 1 || Current FPS: 2.0 || Objects tracked: 12\n",
      "Loading detected frame from file...\n",
      "Processed frame no: 2 || Current FPS: 5.0 || Objects tracked: 12\n",
      "Loading detected frame from file...\n",
      "Track id: 1\n",
      "Time start: [3, 0, 0, 0]\n",
      "Time end: [0, 0, 0, 0]\n",
      "Track id: 2\n",
      "Time start: [0, 3, 0, 0]\n",
      "Time end: [0, 0, 0, 0]\n",
      "Track id: 3\n",
      "Time start: [3, 0, 0, 0]\n",
      "Time end: [0, 0, 0, 0]\n",
      "Track id: 4\n",
      "Time start: [3, 0, 0, 0]\n",
      "Time end: [0, 0, 0, 0]\n",
      "Track id: 5\n",
      "Time start: [0, 0, 3, 0]\n",
      "Time end: [3, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22872/2578335394.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLOv7_DeepSORT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreID_model_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./deep_sort/model_weights/mars-small128.pb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m tracker.track_video(\"./IO_data/input/video/test_video.mp4\",\n\u001b[0m\u001b[0;32m     12\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./IO_data/output/test_video.avi\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mshow_live\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\VSCode\\Speed_Estimation\\speed_estimation\\bridge_wrapper.py\u001b[0m in \u001b[0;36mtrack_video\u001b[1;34m(self, video, output, skip_frames, show_live, count_objects, verbose)\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                 \u001b[0mtrack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_speed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m646\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m341\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m327\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m601\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m412\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1166\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m392\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# draw bbox on screen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\VSCode\\Speed_Estimation\\speed_estimation\\calc_speed.py\u001b[0m in \u001b[0;36mcalculate_speed\u001b[1;34m(track, luLine, ldLine, bbox, frame_idx)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom_center\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeeds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvdlDistance\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeed_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mms2kmh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeeds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from detection_helpers import *\n",
    "from tracking_helpers import *\n",
    "from bridge_wrapper import *\n",
    "from PIL import Image\n",
    "\n",
    "# detect ONLY [person,horses,sports ball]\n",
    "detector = Detector(classes=[2, 5, 6, 7])\n",
    "detector.load_model('yolov7x.pt')\n",
    "\n",
    "tracker = YOLOv7_DeepSORT(reID_model_path=\"./deep_sort/model_weights/mars-small128.pb\", detector=detector)\n",
    "tracker.track_video(\"./IO_data/input/video/test_video.mp4\",\n",
    "                    output=\"./IO_data/output/test_video.avi\",\n",
    "                    show_live=True,\n",
    "                    skip_frames=0,\n",
    "                    count_objects=True,\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "accadaf66c8e4e58dcb0520251c220a63bcc7fcee0d18d2414a72ac010e3c556"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
